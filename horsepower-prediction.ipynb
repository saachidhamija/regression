{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis: Horsepower & Electricity Consumption Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Utility Functions\n",
    "\n",
    "## Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train 4 regression models: Linear, Polynomial (degree 2, 3, 4)\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary with model names as keys and predictions as values\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # Model 1: Linear Regression\n",
    "    model_linear = LinearRegression()\n",
    "    model_linear.fit(X_train, y_train)\n",
    "    models['Linear Regression'] = {\n",
    "        'y_pred_train': model_linear.predict(X_train),\n",
    "        'y_pred_test': model_linear.predict(X_test)\n",
    "    }\n",
    "\n",
    "    # Model 2: Polynomial Regression (Degree 2)\n",
    "    poly_features_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly2 = poly_features_2.fit_transform(X_train)\n",
    "    X_test_poly2 = poly_features_2.transform(X_test)\n",
    "    model_poly2 = LinearRegression()\n",
    "    model_poly2.fit(X_train_poly2, y_train)\n",
    "    models['Polynomial (Degree 2)'] = {\n",
    "        'y_pred_train': model_poly2.predict(X_train_poly2),\n",
    "        'y_pred_test': model_poly2.predict(X_test_poly2)\n",
    "    }\n",
    "\n",
    "    # Model 3: Polynomial Regression (Degree 3)\n",
    "    poly_features_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "    X_train_poly3 = poly_features_3.fit_transform(X_train)\n",
    "    X_test_poly3 = poly_features_3.transform(X_test)\n",
    "    model_poly3 = LinearRegression()\n",
    "    model_poly3.fit(X_train_poly3, y_train)\n",
    "    models['Polynomial (Degree 3)'] = {\n",
    "        'y_pred_train': model_poly3.predict(X_train_poly3),\n",
    "        'y_pred_test': model_poly3.predict(X_test_poly3)\n",
    "    }\n",
    "\n",
    "    # Model 4: Polynomial Regression (Degree 4)\n",
    "    poly_features_4 = PolynomialFeatures(degree=4, include_bias=False)\n",
    "    X_train_poly4 = poly_features_4.fit_transform(X_train)\n",
    "    X_test_poly4 = poly_features_4.transform(X_test)\n",
    "    model_poly4 = LinearRegression()\n",
    "    model_poly4.fit(X_train_poly4, y_train)\n",
    "    models['Polynomial (Degree 4)'] = {\n",
    "        'y_pred_train': model_poly4.predict(X_train_poly4),\n",
    "        'y_pred_test': model_poly4.predict(X_test_poly4)\n",
    "    }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, y_train, y_test, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate models and create results table\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with evaluation metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, predictions in models.items():\n",
    "        # Training metrics\n",
    "        mse_train = mean_squared_error(y_train, predictions['y_pred_train'])\n",
    "        mae_train = mean_absolute_error(y_train, predictions['y_pred_train'])\n",
    "        r2_train = r2_score(y_train, predictions['y_pred_train'])\n",
    "\n",
    "        # Test metrics\n",
    "        mse_test = mean_squared_error(y_test, predictions['y_pred_test'])\n",
    "        mae_test = mean_absolute_error(y_test, predictions['y_pred_test'])\n",
    "        r2_test = r2_score(y_test, predictions['y_pred_test'])\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'MSE (Train)': round(mse_train, 4),\n",
    "            'MAE (Train)': round(mae_train, 4),\n",
    "            'R² (Train)': round(r2_train, 4),\n",
    "            'MSE (Test)': round(mse_test, 4),\n",
    "            'MAE (Test)': round(mae_test, 4),\n",
    "            'R² (Test)': round(r2_test, 4)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    title = f\"Evaluation Metrics for All Models\"\n",
    "    if dataset_name:\n",
    "        title += f\" ({dataset_name})\"\n",
    "    print(f\"{title}:\\n\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Horsepower Prediction\n",
    "\n",
    "## 1. Loading the Dataset\n",
    "\n",
    "Dataset: [Fuel Consumption Based on HP - Linear Regression](https://www.kaggle.com/datasets/ohiedulhaquemdasad/fuel-consumption-based-on-hp-linear-regression/data)\n",
    "\n",
    "This dataset contains:\n",
    "- **Horse Power**: Engine horsepower (feature)\n",
    "- **Fuel Economy (MPG)**: Miles per gallon (target variable)\n",
    "\n",
    "We'll predict Fuel Economy based on Horse Power using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horse Power</th>\n",
       "      <th>Fuel Economy (MPG)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.770799</td>\n",
       "      <td>29.344195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.326567</td>\n",
       "      <td>24.695934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219.262465</td>\n",
       "      <td>23.952010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187.310009</td>\n",
       "      <td>23.384546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218.594340</td>\n",
       "      <td>23.426739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Horse Power  Fuel Economy (MPG)\n",
       "0   118.770799           29.344195\n",
       "1   176.326567           24.695934\n",
       "2   219.262465           23.952010\n",
       "3   187.310009           23.384546\n",
       "4   218.594340           23.426739"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_hp = pd.read_csv('FuelEconomy.csv')\n",
    "\n",
    "# Display first few rows\n",
    "df_hp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (100, 2)\n",
      "\n",
      "Column Names:\n",
      "['Horse Power', 'Fuel Economy (MPG)']\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Horse Power         100 non-null    float64\n",
      " 1   Fuel Economy (MPG)  100 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.7 KB\n",
      "\n",
      "Basic Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horse Power</th>\n",
       "      <th>Fuel Economy (MPG)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>213.676190</td>\n",
       "      <td>23.178501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.061726</td>\n",
       "      <td>4.701666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.996514</td>\n",
       "      <td>20.439516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>218.928402</td>\n",
       "      <td>23.143192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>251.706476</td>\n",
       "      <td>26.089933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Horse Power  Fuel Economy (MPG)\n",
       "count   100.000000          100.000000\n",
       "mean    213.676190           23.178501\n",
       "std      62.061726            4.701666\n",
       "min      50.000000           10.000000\n",
       "25%     174.996514           20.439516\n",
       "50%     218.928402           23.143192\n",
       "75%     251.706476           26.089933\n",
       "max     350.000000           35.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Shape:\", df_hp.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_hp.columns.tolist())\n",
    "print(\"\\nDataset Info:\")\n",
    "df_hp.info()\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df_hp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "Horse Power           0\n",
      "Fuel Economy (MPG)    0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "\n",
      "Percentage of missing values:\n",
      "Horse Power           0.0\n",
      "Fuel Economy (MPG)    0.0\n",
      "dtype: float64\n",
      "\n",
      "✓ No missing values found in the dataset!\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_counts_hp = df_hp.isnull().sum()\n",
    "print(missing_counts_hp)\n",
    "print(f\"\\nTotal missing values: {missing_counts_hp.sum()}\")\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((missing_counts_hp / len(df_hp) * 100).round(2))\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_counts_hp.sum() > 0:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    missing_counts_hp.plot(kind='bar')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found in the dataset!\")\n",
    "\n",
    "print(\"\\nDuplicate Rows:\", df_hp.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 70 (70.0%)\n",
      "Test set size: 30 (30.0%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X_hp = df_hp[['Horse Power']]  # Features\n",
    "y_hp = df_hp['Fuel Economy (MPG)']  # Target variable\n",
    "\n",
    "# 70/30 train-test split\n",
    "X_train_hp, X_test_hp, y_train_hp, y_test_hp = train_test_split(X_hp, y_hp, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train_hp.shape[0]} ({X_train_hp.shape[0]/len(df_hp)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test_hp.shape[0]} ({X_test_hp.shape[0]/len(df_hp)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We'll train 4 different regression models to predict Fuel Economy from Horse Power:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Descriptions\n",
    "\n",
    "**Model 1: Linear Regression**\n",
    "- **Equation:** y = β₀ + β₁x\n",
    "- **Description:** Fits a straight line to the data. The relationship between Horse Power and Fuel Economy is modeled as a linear function with one coefficient for the feature and an intercept term.\n",
    "\n",
    "**Model 2: Polynomial Regression (Degree 2)**\n",
    "- **Equation:** y = β₀ + β₁x + β₂x²\n",
    "- **Description:** Fits a quadratic curve to the data. This allows for a curved relationship where the effect of Horse Power on Fuel Economy can change direction, capturing non-linear patterns with a single bend.\n",
    "\n",
    "**Model 3: Polynomial Regression (Degree 3)**\n",
    "- **Equation:** y = β₀ + β₁x + β₂x² + β₃x³\n",
    "- **Description:** Fits a cubic curve with two bends, allowing for more complex non-linear relationships. This can capture S-shaped patterns and more intricate variations in how Horse Power affects Fuel Economy.\n",
    "\n",
    "**Model 4: Polynomial Regression (Degree 4)**\n",
    "- **Equation:** y = β₀ + β₁x + β₂x² + β₃x³ + β₄x⁴\n",
    "- **Description:** Fits a quartic curve with three bends, providing maximum flexibility to capture highly complex non-linear patterns. This model can fit very intricate relationships but may be prone to overfitting with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models using the utility function\n",
    "models_hp = train_models(X_train_hp, y_train_hp, X_test_hp, y_test_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics\n",
    "\n",
    "We'll evaluate each model using three key metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R²)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Metric Descriptions\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "- **Formula:** MSE = (1/n) × Σ(yᵢ - ŷᵢ)²\n",
    "- **Description:** Measures the average squared difference between predicted and actual values. It penalizes larger errors more heavily due to squaring. Lower values indicate better model performance. Units are squared (e.g., MPG²).\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "- **Formula:** MAE = (1/n) × Σ|yᵢ - ŷᵢ|\n",
    "- **Description:** Measures the average absolute difference between predicted and actual values. It treats all errors equally and is more interpretable than MSE since it's in the same units as the target variable (e.g., MPG). Lower values indicate better performance.\n",
    "\n",
    "**R-squared (R²):**\n",
    "- **Formula:** R² = 1 - (SS_res / SS_tot) where SS_res = Σ(yᵢ - ŷᵢ)² and SS_tot = Σ(yᵢ - ȳ)²\n",
    "- **Description:** Measures the proportion of variance in the target variable explained by the model. Values range from -∞ to 1, where 1 indicates perfect predictions, 0 means the model performs as well as predicting the mean, and negative values indicate worse performance than the mean. Higher values indicate better model fit.\n",
    "\n",
    "### 5.2 Practical Interpretation\n",
    "\n",
    "**In the context of predicting Fuel Economy (MPG) from Horse Power:**\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "- **What it means:** On average, how many MPG off is our prediction?\n",
    "- **Example:** If MAE = 1.2 MPG, this means our model's predictions are typically off by about 1.2 miles per gallon. If a car actually gets 25 MPG, we might predict anywhere from 23.8 to 26.2 MPG on average.\n",
    "- **Why it's useful:** Easy to understand - it's in the same units as what we're predicting. A car buyer can easily grasp \"the model is usually within 1-2 MPG of the actual fuel economy.\"\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "- **What it means:** How much do large prediction errors hurt our model?\n",
    "- **Example:** If MSE = 2.5 MPG², this tells us about the magnitude of errors, but it's harder to interpret directly. However, if we have two models and one has MSE = 2.0 and another has MSE = 3.0, the first is better.\n",
    "- **Why it's useful:** Penalizes big mistakes more than small ones. If you're building a model for car manufacturers, you care more about avoiding predictions that are way off (like predicting 30 MPG when it's actually 20 MPG) than small errors. MSE helps identify models that avoid these large errors.\n",
    "\n",
    "**R-squared (R²):**\n",
    "- **What it means:** What percentage of the variation in fuel economy can we explain using horsepower?\n",
    "- **Example:** If R² = 0.91 (or 91%), this means horsepower explains 91% of why different cars have different fuel economies. The remaining 9% is due to other factors (weight, aerodynamics, driving conditions, etc.).\n",
    "- **Why it's useful:** Gives a sense of how well the model captures the relationship. An R² of 0.91 is excellent - it means horsepower is a very strong predictor. If R² was 0.50, it would mean horsepower only explains half the variation, suggesting other factors are equally important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for All Models (Horsepower Prediction):\n",
      "\n",
      "                Model  MSE (Train)  MAE (Train)  R² (Train)  MSE (Test)  MAE (Test)  R² (Test)\n",
      "    Linear Regression       2.1157       1.2100      0.9063      1.6749      1.0313     0.9133\n",
      "Polynomial (Degree 2)       2.1151       1.2103      0.9063      1.6570      1.0254     0.9142\n",
      "Polynomial (Degree 3)       2.0606       1.2115      0.9088      1.9037      1.0872     0.9015\n",
      "Polynomial (Degree 4)       1.9177       1.1683      0.9151      2.5485      1.2034     0.8681\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models and create results table\n",
    "results_df_hp = evaluate_models(models_hp, y_train_hp, y_test_hp, \"Horsepower Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE (Train)</th>\n",
       "      <th>MAE (Train)</th>\n",
       "      <th>R² (Train)</th>\n",
       "      <th>MSE (Test)</th>\n",
       "      <th>MAE (Test)</th>\n",
       "      <th>R² (Test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2.1157</td>\n",
       "      <td>1.2100</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>1.6749</td>\n",
       "      <td>1.0313</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial (Degree 2)</td>\n",
       "      <td>2.1151</td>\n",
       "      <td>1.2103</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>1.6570</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial (Degree 3)</td>\n",
       "      <td>2.0606</td>\n",
       "      <td>1.2115</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>1.9037</td>\n",
       "      <td>1.0872</td>\n",
       "      <td>0.9015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial (Degree 4)</td>\n",
       "      <td>1.9177</td>\n",
       "      <td>1.1683</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>2.5485</td>\n",
       "      <td>1.2034</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  MSE (Train)  MAE (Train)  R² (Train)  MSE (Test)  \\\n",
       "0      Linear Regression       2.1157       1.2100      0.9063      1.6749   \n",
       "1  Polynomial (Degree 2)       2.1151       1.2103      0.9063      1.6570   \n",
       "2  Polynomial (Degree 3)       2.0606       1.2115      0.9088      1.9037   \n",
       "3  Polynomial (Degree 4)       1.9177       1.1683      0.9151      2.5485   \n",
       "\n",
       "   MAE (Test)  R² (Test)  \n",
       "0      1.0313     0.9133  \n",
       "1      1.0254     0.9142  \n",
       "2      1.0872     0.9015  \n",
       "3      1.2034     0.8681  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display formatted table\n",
    "results_df_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "### Q. Which model performs best on the test set and why?\n",
    "A. For this dataset, we only care about typical errors, and do not need to avoid large errors, meaning we need to prioritize MAE, which calculates the absolute error, over MSE, which calculates the squared error, leading to heavier penalization of larger errors. According to our evalulation metrics, the model that has the best (smallest) MAE is Polynomial (degree 2). This means that, on average, the model's predictions are wrong by 1.0254 MPG. The MSE for this test case is also the smallest among all, at 1.6570. Lastly, to verify the fact that this model performs the best, we turn our eyes towards the R^2 value. Polynomial (degree 2) has the highest R^2 value as well, meaning our model captures variations well. Since Polynomial (degree 2) outperforms all other models in all of these metrics, we can confidently say that it performs best on the test set.\n",
    "\n",
    "### Q. Does increasing polynomial degree always improve performance? If not, explain what you observe.\n",
    "A. In the context of this dataset, increasing the polynomial degree does not work in favor of overall model performance. As seen in our primary metric, MAE, the test MAE values get bigger as the degree of our polynomial, meaning that the average absolute error increases from 1.0250 MPG at degree 2 to 1.2034 MPG at degree 4. Similarly, MSE increases from 1.6570 MPG to 2.5485 MPG. Both of these increases imply that the model performance decreases. To reinforce this, we notice how the R^2 value also falls down as degree increases, meaning the model's ability to capture variance decreases.\n",
    "\n",
    "### Q. If a model performs unexpectedly poorly (e.g., low R2 or large test error), propose at least two plausible reasons, such as:\n",
    "- underfitting vs overfitting,\n",
    "- weak relationship between features and target,\n",
    "- outliers or noise in the data,\n",
    "- insufficient feature information for predicting HP\n",
    "\n",
    "One plausible reason is overfitting. In this dataset, higher-degree polynomial models (e.g., degree 3) show a noticeable increase in test MAE and MSE compared to their training errors. This gap indicates that the model is fitting noise or outliers in the training data rather than learning the underlying relationship. As a result, the model performs well on training data but generalizes poorly to unseen test data.\n",
    "\n",
    "A second possible reason is the presence of outliers or noise in the dataset. Polynomial models with higher degrees are more sensitive to extreme values, which can cause the model to contort its curve to fit these points. This leads to increased prediction error on the test set and a reduction in R², as the model fails to capture the true data-generating trend.\n",
    "\n",
    "Additionally, poor performance may stem from a weak relationship between the input features and the target variable (HP). If the available features do not contain sufficient information to accurately predict HP, even more complex models will struggle, resulting in low R² and large test errors regardless of model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Electricity Consumption Prediction\n",
    "\n",
    "## 1. Loading the Dataset\n",
    "\n",
    "This dataset contains weather features and daily electricity consumption:\n",
    "- **AWND**: Average daily wind speed (mph)\n",
    "- **PRCP**: Precipitation (inches)\n",
    "- **TMAX**: Maximum temperature (°F)\n",
    "- **TMIN**: Minimum temperature (°F)\n",
    "- **daily_consumption**: Daily electricity consumption (target variable)\n",
    "\n",
    "We'll predict daily electricity consumption based on weather features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>daily_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1209.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-17</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3390.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-18</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2203.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-19</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1666.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2225.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  AWND  PRCP  TMAX  TMIN  daily_consumption\n",
       "0  2006-12-16   2.5   0.0  10.6   5.0           1209.176\n",
       "1  2006-12-17   2.6   0.0  13.3   5.6           3390.460\n",
       "2  2006-12-18   2.4   0.0  15.0   6.7           2203.826\n",
       "3  2006-12-19   2.4   0.0   7.2   2.2           1666.194\n",
       "4  2006-12-20   2.4   0.0   7.2   1.1           2225.748"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the electricity consumption dataset\n",
    "df_electricity = pd.read_csv('electricity_consumption_based_weather_dataset.csv')\n",
    "\n",
    "# Display first few rows\n",
    "df_electricity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1433, 6)\n",
      "\n",
      "Column Names:\n",
      "['date', 'AWND', 'PRCP', 'TMAX', 'TMIN', 'daily_consumption']\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1433 entries, 0 to 1432\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   date               1433 non-null   object \n",
      " 1   AWND               1418 non-null   float64\n",
      " 2   PRCP               1433 non-null   float64\n",
      " 3   TMAX               1433 non-null   float64\n",
      " 4   TMIN               1433 non-null   float64\n",
      " 5   daily_consumption  1433 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 67.3+ KB\n",
      "\n",
      "Basic Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>daily_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1418.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.642313</td>\n",
       "      <td>3.800488</td>\n",
       "      <td>17.187509</td>\n",
       "      <td>9.141242</td>\n",
       "      <td>1561.078061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.140021</td>\n",
       "      <td>10.973436</td>\n",
       "      <td>10.136415</td>\n",
       "      <td>9.028417</td>\n",
       "      <td>606.819667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.900000</td>\n",
       "      <td>-14.400000</td>\n",
       "      <td>14.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1165.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>1542.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>1893.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.200000</td>\n",
       "      <td>192.300000</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>4773.386000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AWND         PRCP         TMAX         TMIN  daily_consumption\n",
       "count  1418.000000  1433.000000  1433.000000  1433.000000        1433.000000\n",
       "mean      2.642313     3.800488    17.187509     9.141242        1561.078061\n",
       "std       1.140021    10.973436    10.136415     9.028417         606.819667\n",
       "min       0.000000     0.000000    -8.900000   -14.400000          14.218000\n",
       "25%       1.800000     0.000000     8.900000     2.200000        1165.700000\n",
       "50%       2.400000     0.000000    17.800000     9.400000        1542.650000\n",
       "75%       3.300000     1.300000    26.100000    17.200000        1893.608000\n",
       "max      10.200000   192.300000    39.400000    27.200000        4773.386000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Shape:\", df_electricity.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_electricity.columns.tolist())\n",
    "print(\"\\nDataset Info:\")\n",
    "df_electricity.info()\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df_electricity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "date                  0\n",
      "AWND                 15\n",
      "PRCP                  0\n",
      "TMAX                  0\n",
      "TMIN                  0\n",
      "daily_consumption     0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 15\n",
      "\n",
      "Percentage of missing values:\n",
      "date                 0.00\n",
      "AWND                 1.05\n",
      "PRCP                 0.00\n",
      "TMAX                 0.00\n",
      "TMIN                 0.00\n",
      "daily_consumption    0.00\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_counts_electricity = df_electricity.isnull().sum()\n",
    "print(missing_counts_electricity)\n",
    "print(f\"\\nTotal missing values: {missing_counts_electricity.sum()}\")\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((missing_counts_electricity / len(df_electricity) * 100).round(2))\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_counts_electricity.sum() > 0:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    missing_counts_electricity.plot(kind='bar')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found in the dataset!\")\n",
    "\n",
    "print(\"\\nDuplicate Rows:\", df_electricity.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Missing values handled!\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values before train-test split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check if there are missing values\n",
    "if df_electricity.isnull().sum().sum() > 0:\n",
    "    print(\"Handling missing values...\")\n",
    "\n",
    "    # For features: use mean imputation\n",
    "    feature_cols = ['AWND', 'PRCP', 'TMAX', 'TMIN']\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_electricity[feature_cols] = imputer.fit_transform(df_electricity[feature_cols])\n",
    "\n",
    "    # For target: drop rows with missing target values (critical for supervised learning)\n",
    "    if df_electricity['daily_consumption'].isnull().sum() > 0:\n",
    "        print(f\"Dropping {df_electricity['daily_consumption'].isnull().sum()} rows with missing target values\")\n",
    "        df_electricity = df_electricity.dropna(subset=['daily_consumption'])\n",
    "\n",
    "    print(\"Missing values handled!\")\n",
    "    print(f\"Remaining missing values: {df_electricity.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"No missing values to handle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1003 (70.0%)\n",
      "Test set size: 430 (30.0%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target for electricity dataset\n",
    "# Using weather features (excluding date)\n",
    "X_electricity = df_electricity[['AWND', 'PRCP', 'TMAX', 'TMIN']]  # Features\n",
    "y_electricity = df_electricity['daily_consumption']  # Target variable\n",
    "\n",
    "# 70/30 train-test split\n",
    "X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(X_electricity, y_electricity, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train_e.shape[0]} ({X_train_e.shape[0]/len(df_electricity)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test_e.shape[0]} ({X_test_e.shape[0]/len(df_electricity)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We'll train 4 different regression models to predict daily electricity consumption from weather features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Descriptions\n",
    "\n",
    "**Model 1: Linear Regression**\n",
    "- **Equation:** y = β₀ + β₁x₁ + β₂x₂ + β₃x₃ + β₄x₄\n",
    "- **Description:** Fits a linear hyperplane to the data. The relationship between weather features (wind, precipitation, max/min temperature) and electricity consumption is modeled as a linear combination of all features with an intercept term.\n",
    "\n",
    "**Model 2: Polynomial Regression (Degree 2)**\n",
    "- **Equation:** y = β₀ + Σβᵢxᵢ + Σβᵢⱼxᵢxⱼ\n",
    "- **Description:** Fits a quadratic surface to the data. This allows for non-linear relationships and interactions between weather features, capturing how combinations of features (e.g., high temperature and high precipitation) affect electricity consumption.\n",
    "\n",
    "**Model 3: Polynomial Regression (Degree 3)**\n",
    "- **Equation:** y = β₀ + Σβᵢxᵢ + Σβᵢⱼxᵢxⱼ + Σβᵢⱼₖxᵢxⱼxₖ\n",
    "- **Description:** Fits a cubic surface with more complex non-linear relationships. This can capture higher-order interactions between weather features and more intricate patterns in how weather conditions affect electricity consumption.\n",
    "\n",
    "**Model 4: Polynomial Regression (Degree 4)**\n",
    "- **Equation:** y = β₀ + Σβᵢxᵢ + Σβᵢⱼxᵢxⱼ + Σβᵢⱼₖxᵢxⱼxₖ + Σβᵢⱼₖₗxᵢxⱼxₖxₗ\n",
    "- **Description:** Fits a quartic surface with maximum flexibility to capture highly complex non-linear patterns and high-order feature interactions. This model can fit very intricate relationships but may be prone to overfitting with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models using the utility function\n",
    "models_electricity = train_models(X_train_e, y_train_e, X_test_e, y_test_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics\n",
    "\n",
    "We'll evaluate each model using three key metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R²)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Metric Descriptions\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "- **Formula:** MSE = (1/n) × Σ(yᵢ - ŷᵢ)²\n",
    "- **Description:** Measures the average squared difference between predicted and actual values. It penalizes larger errors more heavily due to squaring. Lower values indicate better model performance. Units are squared (e.g., consumption²).\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "- **Formula:** MAE = (1/n) × Σ|yᵢ - ŷᵢ|\n",
    "- **Description:** Measures the average absolute difference between predicted and actual values. It treats all errors equally and is more interpretable than MSE since it's in the same units as the target variable (e.g., consumption units). Lower values indicate better performance.\n",
    "\n",
    "**R-squared (R²):**\n",
    "- **Formula:** R² = 1 - (SS_res / SS_tot) where SS_res = Σ(yᵢ - ŷᵢ)² and SS_tot = Σ(yᵢ - ȳ)²\n",
    "- **Description:** Measures the proportion of variance in the target variable explained by the model. Values range from -∞ to 1, where 1 indicates perfect predictions, 0 means the model performs as well as predicting the mean, and negative values indicate worse performance than the mean. Higher values indicate better model fit.\n",
    "\n",
    "### 5.2 Practical Interpretation\n",
    "\n",
    "**In the context of predicting Daily Electricity Consumption from Weather Features:**\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "- **What it means:** On average, how many consumption units off is our prediction?\n",
    "- **Example:** If MAE = 200 units, this means our model's predictions are typically off by about 200 consumption units. If actual consumption is 1500 units, we might predict anywhere from 1300 to 1700 units on average.\n",
    "- **Why it's useful:** Easy to understand - it's in the same units as what we're predicting. Energy managers can easily grasp \"the model is usually within 200 units of the actual consumption.\"\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "- **What it means:** How much do large prediction errors hurt our model?\n",
    "- **Example:** If MSE = 50000 units², this tells us about the magnitude of errors, but it's harder to interpret directly. However, if we have two models and one has MSE = 40000 and another has MSE = 60000, the first is better.\n",
    "- **Why it's useful:** Penalizes big mistakes more than small ones. For energy grid management, avoiding predictions that are way off (like predicting 2000 units when it's actually 1000 units) is critical. MSE helps identify models that avoid these large errors.\n",
    "\n",
    "**R-squared (R²):**\n",
    "- **What it means:** What percentage of the variation in electricity consumption can we explain using weather features?\n",
    "- **Example:** If R² = 0.75 (or 75%), this means weather features explain 75% of why different days have different electricity consumption. The remaining 25% is due to other factors (day of week, holidays, economic activity, etc.).\n",
    "- **Why it's useful:** Gives a sense of how well the model captures the relationship. An R² of 0.75 is good - it means weather is a strong predictor. If R² was 0.30, it would mean weather only explains 30% of the variation, suggesting other factors are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for All Models (Electricity Consumption):\n",
      "\n",
      "                Model  MSE (Train)  MAE (Train)  R² (Train)  MSE (Test)  MAE (Test)  R² (Test)\n",
      "    Linear Regression  274826.3121     387.0474      0.2729 237216.8887    365.5832     0.3115\n",
      "Polynomial (Degree 2)  268041.4446     382.0871      0.2909 234831.8534    362.9045     0.3184\n",
      "Polynomial (Degree 3)  261191.0805     377.7388      0.3090 238445.6415    369.0937     0.3079\n",
      "Polynomial (Degree 4)  253602.6870     374.7296      0.3291 408466.1815    415.2872    -0.1855\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models and create results table\n",
    "results_df_electricity = evaluate_models(models_electricity, y_train_e, y_test_e, \"Electricity Consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE (Train)</th>\n",
       "      <th>MAE (Train)</th>\n",
       "      <th>R² (Train)</th>\n",
       "      <th>MSE (Test)</th>\n",
       "      <th>MAE (Test)</th>\n",
       "      <th>R² (Test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>274826.3121</td>\n",
       "      <td>387.0474</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>237216.8887</td>\n",
       "      <td>365.5832</td>\n",
       "      <td>0.3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial (Degree 2)</td>\n",
       "      <td>268041.4446</td>\n",
       "      <td>382.0871</td>\n",
       "      <td>0.2909</td>\n",
       "      <td>234831.8534</td>\n",
       "      <td>362.9045</td>\n",
       "      <td>0.3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial (Degree 3)</td>\n",
       "      <td>261191.0805</td>\n",
       "      <td>377.7388</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>238445.6415</td>\n",
       "      <td>369.0937</td>\n",
       "      <td>0.3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial (Degree 4)</td>\n",
       "      <td>253602.6870</td>\n",
       "      <td>374.7296</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>408466.1815</td>\n",
       "      <td>415.2872</td>\n",
       "      <td>-0.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  MSE (Train)  MAE (Train)  R² (Train)   MSE (Test)  \\\n",
       "0      Linear Regression  274826.3121     387.0474      0.2729  237216.8887   \n",
       "1  Polynomial (Degree 2)  268041.4446     382.0871      0.2909  234831.8534   \n",
       "2  Polynomial (Degree 3)  261191.0805     377.7388      0.3090  238445.6415   \n",
       "3  Polynomial (Degree 4)  253602.6870     374.7296      0.3291  408466.1815   \n",
       "\n",
       "   MAE (Test)  R² (Test)  \n",
       "0    365.5832     0.3115  \n",
       "1    362.9045     0.3184  \n",
       "2    369.0937     0.3079  \n",
       "3    415.2872    -0.1855  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display formatted table\n",
    "results_df_electricity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "### Q. Which model generalizes best (best test performance), and what does that tell you about the\n",
    "relationship between weather and electricity usage?\n",
    "A. The best test performance is for the model Polynomial (degree 2). This is proved by looking at the MSE and MAE values for all the models. While all of them are high, Polynomial (degree 2) has the lowest MSE and MAE values as compared to other models at 234831.8534 and 362.9045, respectively. This is reinforced by looking at the R^2 values, wherein Polynomial (degree 2) has the largest value (closest to 1) at 0.3184. This means that the model is the most robust, has the least large errors, and matches most of the variance, thus, it generalizes the best. However, the fact that the MSE and MAE values are so high, and R^2 is so low, means that there does not exist a relationship between weather and electricity usage that can be accurately captured using linear or polynomial regression.\n",
    "\n",
    "### Q. Does increasing polynomial degree always improve performance? If not, explain what you observe.\n",
    "A. No. As can be seen from the test MSE, MAE, and R^2 values, the MSE and MAE values increase as the polynomial degree becomes greater, and R^2 decreases as the degree increases. Thus, we can say that increasing the polynomial degree does not improve performance for this dataset.\n",
    "\n",
    "### Q. If a model performs unexpectedly poorly (e.g., low R2 or large test error), propose at least two plausible reasons, such as:\n",
    "- underfitting vs overfitting,\n",
    "- weak relationship between features and target,\n",
    "- outliers or noise in the data,\n",
    "- insufficient feature information for predicting electricity consumption\n",
    "\n",
    "A. An interesting phenomenon is also noticed for the Polynomial (degree 4) model. The train MSE, MAE, and R^2 values seem to be falling at a constant rate. However, this is not reflected in the test values for the same model, which seem like outliers, and are extremely skewed. This could be because the degree 4 polynomial model overfits the data. Meaning it learns the pattern of the training data well, leading to fairly consistent evaluation metric values. However, it is not able to generalize well for the test data. This could be because the training data has outliers or noise, which is what the model overfits to, leading to reduced performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
