{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Power Plans Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "# (file copied into this repo as `usina_with_outliers.csv`)\n",
        "df = pd.read_csv('usina_with_outliers.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Model Choice: Linear Regression (OLS)\n",
        "- I chose OLS for this dataset since Lasso Regression try to suppress outliers. However, for this Python Notebook's analysis to be relevant to Cook's distance (which calculates the difference removing a data point makes on a model), the outliers need to be considered in our analysis, rather than smoothed. OLS is intentionally sensitive to influential observations, which allows Cook's distance to effectively identify points that disproportionally affect the fitted model.\n",
        "\n",
        "### Library Choice: Statsmodels OLS\n",
        "- I chose Statsmodels since it is made for diagnostics, however, scikit-learn is built for predicitons. Statsmodels gives us access to all of the metrics Cook's distance depends on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 70/30 random split (reproducible)\n",
        "train_df, test_df = train_test_split(df, test_size=0.30, random_state=42)\n",
        "\n",
        "# Quick sanity-check on sizes\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "print(f\"Train rows: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test rows:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Reset indices for clean train/test frames\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Fit OLS on training data: predict PE from AT, V, AP, RH\n",
        "X = train_df[['AT', 'V', 'AP', 'RH']]\n",
        "y = train_df['PE']\n",
        "\n",
        "X_const = sm.add_constant(X)\n",
        "ols_model = sm.OLS(y, X_const).fit()\n",
        "\n",
        "# Cook's distance for each training point\n",
        "influence = ols_model.get_influence()\n",
        "cooks_d = influence.cooks_distance[0]\n",
        "\n",
        "# Threshold rule: 4/n\n",
        "n = len(train_df)\n",
        "threshold = 4 / n\n",
        "\n",
        "train_df_with_cooks = train_df.copy()\n",
        "train_df_with_cooks['cooks_distance'] = cooks_d\n",
        "train_df_with_cooks['is_outlier'] = train_df_with_cooks['cooks_distance'] > threshold\n",
        "\n",
        "print(f\"n (train) = {n}\")\n",
        "print(f\"Cook's distance threshold (4/n) = {threshold:.6f}\")\n",
        "print(f\"Outliers detected = {train_df_with_cooks['is_outlier'].sum()}\")\n",
        "\n",
        "# Remove outliers\n",
        "train_df_no_outliers = train_df_with_cooks.loc[~train_df_with_cooks['is_outlier']].drop(columns=['is_outlier'])\n",
        "\n",
        "# Save cleaned training data\n",
        "train_df_no_outliers.to_csv('usina.csv', index=False)\n",
        "print(\"Saved cleaned dataset to usina.csv\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
